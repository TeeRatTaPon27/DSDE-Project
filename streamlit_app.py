# import streamlit as st
# import pandas as pd
# import re
# import time
# from sklearn.cluster import DBSCAN
# import pydeck as pdk
# import numpy as np

# def prepare_map_data(df):
#     progress = st.progress(0, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà...")
#     step = 0

#     total_step = 5

#     # 1) ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå lat/lon
#     step += 1
#     progress.progress(int(100 * step/total_step),
#                       text=f"‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ... ({step}/{total_step})")
#     time.sleep(0.1)

#     # 2) ‡∏•‡∏ö‡∏Ñ‡πà‡∏≤ NaN
#     step += 1
#     df = df.dropna(subset=["lat", "lon"])
#     progress.progress(int(100 * step/total_step),
#                       text=f"‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ... ({step}/{total_step})")
#     time.sleep(0.1)

#     # 3) Convert type
#     step += 1
#     df["lat"] = df["lat"].astype(float)
#     df["lon"] = df["lon"].astype(float)
#     progress.progress(int(100 * step/total_step),
#                       text=f"‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö lat/lon ... ({step}/{total_step})")
#     time.sleep(0.05)

#     # 4) Limit number of points (optional) ‚Üí ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô map ‡∏ä‡πâ‡∏≤
#     step += 1
#     if len(df) > 30000:  
#         df = df.sample(30000)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î 30k ‡∏à‡∏∏‡∏î
#     progress.progress(int(100 * step/total_step),
#                       text=f"‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ... ({step}/{total_step})")
#     time.sleep(0.1)

#     # 5) ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô
#     step += 1
#     progress.progress(100, text="‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà ‚úì")
#     time.sleep(0.1)

#     return df

# # ---------------------------
# # Load Data with Progress Bar
# # ---------------------------
# @st.cache_data(show_spinner=False)
# def load_data_with_progress():
#     progress = st.progress(0, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
#     status = st.empty()

#     # STEP 1: load CSV
#     progress.progress(20, text="‡πÇ‡∏´‡∏•‡∏î CSV ...")
#     df = pd.read_csv("dataset/df_clean_organization.csv")
#     time.sleep(0.3)

#     # STEP 2: parse type text
#     progress.progress(40, text="‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• type ...")
#     def parse_type(value):
#         if pd.isna(value):
#             return []
#         value = str(value).replace("{", "").replace("}", "")
#         parts = re.split(r'\s*,\s*', value)
#         return [p.strip() for p in parts if p.strip()]
#     df["type_list"] = df["type"].apply(parse_type)
#     time.sleep(0.3)

#     # STEP 3: explode rows
#     progress.progress(60, text="‡πÅ‡∏¢‡∏Å‡πÅ‡∏ñ‡∏ß (explode) ...")
#     df_exploded = df.explode("type_list")
#     df_exploded.rename(columns={"type_list": "type_exploded"}, inplace=True)
#     df_exploded["timestamp_dt"] = pd.to_datetime(df_exploded["timestamp"], errors="coerce")

#     # -----------------------
#     # Clean type_exploded
#     # -----------------------
#     df_exploded['type_exploded'] = df_exploded['type_exploded'].astype(str) \
#         .str.strip() \
#         .str.replace(r"[\[\]']", "", regex=True)
#     df_exploded = df_exploded[df_exploded['type_exploded'] != ""]

#     time.sleep(0.3)

#     # STEP 4: extract coords (‡πÅ‡∏Å‡πâ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏à‡∏£‡∏¥‡∏á: lon, lat)
#     progress.progress(80, text="‡∏î‡∏∂‡∏á lat/lon ‡∏à‡∏≤‡∏Å coords ...")
#     df_exploded['coords'] = df_exploded['coords'].astype(str)
#     df_exploded[['lon', 'lat']] = df_exploded['coords'].str.extract(
#         r'(-?\d+\.\d+)\s*,\s*(-?\d+\.\d+)'
#     ).astype(float)
#     time.sleep(0.3)

#     # STEP 5: drop missing
#     progress.progress(100, text="‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ...")
#     df_exploded = df_exploded.dropna(
#         subset=["lat", "lon", "district", "subdistrict", "type_exploded"]
#     )
#     time.sleep(0.3)

#     status.success("‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

#     return df_exploded

# # ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡πÉ‡∏ô filter
# if 'filter_applied' not in st.session_state:
#     st.session_state['filter_applied'] = False
    
# # ---------------------------
# # Tabs
# # ---------------------------
# tab_load, tab_main = st.tabs(["üìä Loading Status", "üìç Dashboard", "üò∑ PM2.5 Analysis"])

# with tab_load:
#     st.subheader("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
#     df = load_data_with_progress()
#     st.success("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞ cache ‡πÅ‡∏•‡πâ‡∏ß ‚úì")


# # ---------------------------
# # Dashboard (Main)
# # ---------------------------
# with tab_main:
#     # Sidebar Filter
#     st.sidebar.header("Filters")
#     st.write("Columns:", df.columns.tolist())
#     districts = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df["district"].unique())
#     selected_district = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ç‡∏ï", districts)

#     subdistricts = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df["subdistrict"].unique())
#     selected_subdistrict = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏Ç‡∏ß‡∏á", subdistricts)

#     types = sorted(df["type_exploded"].unique())
#     selected_types = st.sidebar.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤", types)

#     # Organization dropdown (‡∏´‡∏•‡∏±‡∏Å)
#     organizations = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df["organization"].dropna().unique())
#     selected_org = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏´‡∏•‡∏±‡∏Å", organizations)

#     # Organization List (‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
#     all_org_lists = sorted(
#         {org for lst in df["organization_list"] for org in lst if isinstance(lst, list)}
#     )
#     selected_org_multi = st.sidebar.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£ (organization_list)", all_org_lists)
    
#     # Filtering
#     df_filtered = df.copy()

#     # ‡πÄ‡∏Ç‡∏ï
#     if selected_district != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
#         df_filtered = df_filtered[df_filtered["district"] == selected_district]

#     # ‡πÅ‡∏Ç‡∏ß‡∏á
#     if selected_subdistrict != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
#         df_filtered = df_filtered[df_filtered["subdistrict"] == selected_subdistrict]

#     # ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤
#     if selected_types:
#         df_filtered = df_filtered[df_filtered["type_exploded"].isin(selected_types)]

#     # ‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏´‡∏•‡∏±‡∏Å
#     if selected_org != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
#         df_filtered = df_filtered[df_filtered["organization"] == selected_org]

#     # ‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (list)
#     if selected_org_multi:
#         df_filtered = df_filtered[
#             df_filtered["organization_list"].apply(
#                 lambda lst: any(o in lst for o in selected_org_multi)
#             )
#         ]
        
    
#     # -----------------------------
#     # Time Filter (Thai Calendar UI)
#     # -----------------------------
#     st.sidebar.subheader("‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ (Timestamp)")

#     # Convert timestamp ‚Üí datetime
#     # progress.progress(50, text="‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ß‡∏•‡∏≤ timestamp ...")
#     # df["timestamp_dt"] = pd.to_datetime(df["timestamp"], errors="coerce")
#     # time.sleep(0.2)
    
#     with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ß‡∏•‡∏≤..."):
#         # Convert timestamp ‚Üí datetime
#         df["timestamp_dt"] = pd.to_datetime(df["timestamp"], errors="coerce")
#         time.sleep(0.2)

#     # default range
#     min_date = df["timestamp_dt"].min().date()
#     max_date = df["timestamp_dt"].max().date()

#     # date UI (show Thai locale)
#     start_date = st.sidebar.date_input("‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (‡∏û.‡∏®.)", min_date)
#     end_date = st.sidebar.date_input("‡∏ß‡∏±‡∏ô‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î (‡∏û.‡∏®.)", max_date)
    
#     confirm_button = st.button('‚úÖ Apply Filters')

#     # filter by datetime
#     df_filtered = df_filtered[
#         (df_filtered["timestamp_dt"].dt.date >= start_date) &
#         (df_filtered["timestamp_dt"].dt.date <= end_date)
#     ]
    
#     # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏´‡∏•‡∏±‡∏Å
#     if selected_org != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":

#         df_org = df[df["organization"] == selected_org]
#         count_cases = len(df_org)

#         if count_cases >= 50:
#             avg_rating = df_org["star"].mean()
#             st.metric("‚≠ê Rating ‡∏Ç‡∏≠‡∏á‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£", f"{avg_rating:.2f}")
#         else:
#             st.info("‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á 50 ‡πÄ‡∏Ñ‡∏™ ‚Äî ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á Rating")
            
#     st.subheader("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤")

#     now = df["timestamp_dt"].max()

#     ranges = {
#         "1 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": now - pd.Timedelta(days=1),
#         "3 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": now - pd.Timedelta(days=3),
#         "7 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": now - pd.Timedelta(days=7),
#         "2 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": now - pd.Timedelta(days=14),
#         "1 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": now - pd.Timedelta(days=30),
#         "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": df["timestamp_dt"].min(),
#     }

#     for label, start_time in ranges.items():
#         count = df_filtered[df_filtered["timestamp_dt"] >= start_time].shape[0]
#         st.write(f"- **{label}:** {count:,} ‡πÄ‡∏Ñ‡∏™")
        
#     # -----------------------------
#     # Recommended Feature 3: Top 10 Bar Chart
#     # -----------------------------
#     st.subheader("‚≠ê Top 10 ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î")

#     if df_filtered.empty:
#         st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
#     else:
#         # 1. Groupby ‡πÅ‡∏•‡∏∞‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™ (Value Counts)
#         top_10_types = df_filtered["type_exploded"].value_counts().nlargest(10).reset_index()
#         top_10_types.columns = ["‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™"]

#         # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Bar Chart ‡∏î‡πâ‡∏ß‡∏¢ Plotly (‡∏´‡∏£‡∏∑‡∏≠ Streamlit's st.bar_chart)
#         import plotly.express as px

#         fig = px.bar(
#             top_10_types,
#             x="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™",
#             y="‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤",
#             orientation='h', # ‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô 
#             title="10 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î",
#             color_discrete_sequence=['#4CAF50'], # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß
#         )
        
#         # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á layout ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
#         fig.update_layout(
#             yaxis={'categoryorder':'total ascending'}, # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å
#             plot_bgcolor='rgba(0,0,0,0)',
#             xaxis=(dict(showgrid=False))
#         )

#         st.plotly_chart(fig, use_container_width=True)
    
#     # --- ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£ (‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏ô‡∏™‡∏∏‡∏î‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏∑‡πà‡∏ô ‡πÜ) ---
#     org_loc_df = pd.read_csv("dataset/bkk_osm_organization_locations.csv")

#     # ‡∏ó‡∏≥ clean ‡∏ä‡∏∑‡πà‡∏≠
#     org_loc_df['name_norm'] = org_loc_df['name'].str.strip().str.lower()
#     df_filtered['organization_norm'] = df_filtered['organization'].fillna("").str.strip().str.lower()

#     # ‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á filter
#     filtered_orgs = df_filtered['organization_norm'].unique()

#     # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
#     org_points = org_loc_df[org_loc_df['name_norm'].isin(filtered_orgs)].copy()

#     # Map
#     # ---------------------------
# # Map with Clustering
# # ---------------------------
# st.header("‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ö‡∏ô‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà (DBSCAN Clustering)")

# if df_filtered.empty:
#     st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
# else:
#     with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà..."):
#         df_map = prepare_map_data(df_filtered)

#         # ---------------------------
#         # DBSCAN Clustering
#         # ---------------------------
#         coords = df_map[["lat", "lon"]].to_numpy()

#         # eps ~ 0.001 ‚âà 100m (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ)
#         clustering = DBSCAN(eps=0.002, min_samples=10).fit(coords)
#         df_map["cluster"] = clustering.labels_
        
#         # ---------------------------
#         # ‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
#         # ---------------------------
#         if selected_org != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
#             highlight_color = [0, 120, 255]   # ‡∏ü‡πâ‡∏≤
#             normal_color = [180, 180, 180]    # ‡πÄ‡∏ó‡∏≤‡∏≠‡πà‡∏≠‡∏ô

#             df_map["color"] = df_map["organization"].apply(
#                 lambda x: highlight_color if x == selected_org else normal_color
#             )

#         elif selected_org_multi:
#             highlight_color = [255, 100, 0]    # ‡∏™‡πâ‡∏°
#             normal_color = [180, 180, 180]

#             df_map["color"] = df_map["organization_list"].apply(
#                 lambda lst: highlight_color if any(o in lst for o in selected_org_multi) else normal_color
#             )

#         else:
#             # ‡πÑ‡∏°‡πà‡∏°‡∏µ filter ‚Üí ‡πÉ‡∏´‡πâ‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤ type_exploded
#             unique_types = sorted(df_map["type_exploded"].unique())
#             type_colors = {
#                 t: [np.random.randint(50,255), np.random.randint(50,255), np.random.randint(50,255)]
#                 for t in unique_types
#             }
#             df_map["color"] = df_map["type_exploded"].apply(lambda t: type_colors[t])

#             # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏µ‡∏™‡∏∏‡πà‡∏°‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞ cluster
#             unique_clusters = sorted(df_map["cluster"].unique())
#             colors = {
#                 c: [np.random.randint(50,255), np.random.randint(50,255), np.random.randint(50,255)]
#                 for c in unique_clusters
#             }
#             # cluster = -1 ‡∏Ñ‡∏∑‡∏≠ noise ‚Üí ‡∏™‡∏µ‡πÄ‡∏ó‡∏≤
#             colors[-1] = [150,150,150]

#             df_map["color"] = df_map["cluster"].apply(lambda c: colors[c])

#          # ---------------------------
#         # PyDeck Visualization
#         # ---------------------------
#         layer = pdk.Layer(
#             "ScatterplotLayer",
#             data=df_map,
#             get_position='[lon, lat]',
#             get_color="color",
#             get_radius=40,
#             pickable=True,
#             opacity=0.7,
#         )
        
#         if len(org_points) > 0:
#             layer_org = pdk.Layer(
#                 "ScatterplotLayer",
#                 data=org_points,
#                 get_position=["lon", "lat"],
#                 get_radius=200,
#                 get_fill_color=[255, 0, 0, 180],
#                 radius_min_pixels=8,
#                 pickable=True,
#             )
#             layers = [layer, layer_org]
#         else:
#             layers = [layer]

#         view_state = pdk.ViewState(
#             latitude=df_map["lat"].mean(),
#             longitude=df_map["lon"].mean(),
#             zoom=11,
#         )

#         r = pdk.Deck(
#             layers=layers,
#             initial_view_state=view_state,
#             tooltip={
#                 "html": "<b>Cluster:</b> {cluster}<br>"
#                         "<b>Type:</b> {type_exploded}<br>"
#                         "<b>Lat:</b> {lat}<br>"
#                         "<b>Lon:</b> {lon}",
#                 "style": {"color": "white"}
#             }
#         )

#         st.pydeck_chart(r)
import streamlit as st
import pandas as pd
import re
import time
from sklearn.cluster import DBSCAN
import pydeck as pdk
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta

# ---------------------------
# Load PM2.5 Data with Progress
# ---------------------------
@st.cache_data(show_spinner=False)
def load_pm25_data_with_progress():
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡∏Ç‡∏≠‡∏á‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø"""
    progress = st.progress(0, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5...")
    
    # STEP 1: load CSV
    progress.progress(25, text="‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå...")
    pm25_df = pd.read_csv("dataset/bkk_pm25_daily_2023_all_fast.csv")
    time.sleep(0.3)
    
    # STEP 2: ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    progress.progress(50, text="‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5...")
    pm25_df.rename(columns={'date': 'date_str'}, inplace=True)
    pm25_df['date_dt'] = pd.to_datetime(pm25_df['date_str'], errors='coerce')
    pm25_df.dropna(subset=['date_dt', 'lon', 'lat', 'pm2_5'], inplace=True)
    
    # STEP 3: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Quarter ‡πÅ‡∏•‡∏∞ Month
    progress.progress(75, text="‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™‡πÅ‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô...")
    pm25_df['quarter'] = pm25_df['date_dt'].dt.quarter
    pm25_df['month'] = pm25_df['date_dt'].dt.month
    pm25_df['year'] = pm25_df['date_dt'].dt.year
    
    # STEP 4: ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•)
    progress.progress(100, text="‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5...")
    time.sleep(0.3)
    
    return pm25_df

def prepare_map_data(df):
    """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà"""
    progress = st.progress(0, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà...")
    step = 0
    total_step = 5

    # 1) ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå lat/lon
    step += 1
    progress.progress(int(100 * step/total_step),
                      text=f"‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ... ({step}/{total_step})")
    time.sleep(0.1)

    # 2) ‡∏•‡∏ö‡∏Ñ‡πà‡∏≤ NaN
    step += 1
    df = df.dropna(subset=["lat", "lon"])
    progress.progress(int(100 * step/total_step),
                      text=f"‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ... ({step}/{total_step})")
    time.sleep(0.1)

    # 3) Convert type
    step += 1
    df["lat"] = df["lat"].astype(float)
    df["lon"] = df["lon"].astype(float)
    progress.progress(int(100 * step/total_step),
                      text=f"‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö lat/lon ... ({step}/{total_step})")
    time.sleep(0.05)

    # 4) Limit number of points (optional) ‚Üí ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô map ‡∏ä‡πâ‡∏≤
    step += 1
    if len(df) > 30000:  
        df = df.sample(30000)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î 30k ‡∏à‡∏∏‡∏î
    progress.progress(int(100 * step/total_step),
                      text=f"‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ... ({step}/{total_step})")
    time.sleep(0.1)

    # 5) ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô
    step += 1
    progress.progress(100, text="‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà ‚úì")
    time.sleep(0.1)

    return df

# ---------------------------
# Load Data with Progress Bar
# ---------------------------
@st.cache_data(show_spinner=False)
def load_data_with_progress():
    progress = st.progress(0, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    status = st.empty()

    # STEP 1: load CSV
    progress.progress(20, text="‡πÇ‡∏´‡∏•‡∏î CSV ...")
    df = pd.read_csv("dataset/df_clean_organization.csv")
    time.sleep(0.3)

    # STEP 2: parse type text
    progress.progress(40, text="‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• type ...")
    def parse_type(value):
        if pd.isna(value):
            return []
        value = str(value).replace("{", "").replace("}", "")
        parts = re.split(r'\s*,\s*', value)
        return [p.strip() for p in parts if p.strip()]
    df["type_list"] = df["type"].apply(parse_type)
    time.sleep(0.3)

    # STEP 3: explode rows
    progress.progress(60, text="‡πÅ‡∏¢‡∏Å‡πÅ‡∏ñ‡∏ß (explode) ...")
    df_exploded = df.explode("type_list")
    df_exploded.rename(columns={"type_list": "type_exploded"}, inplace=True)
    df_exploded["timestamp_dt"] = pd.to_datetime(df_exploded["timestamp"], errors="coerce")

    # -----------------------
    # Clean type_exploded
    # -----------------------
    df_exploded['type_exploded'] = df_exploded['type_exploded'].astype(str) \
        .str.strip() \
        .str.replace(r"[\[\]']", "", regex=True)
    df_exploded = df_exploded[df_exploded['type_exploded'] != ""]

    time.sleep(0.3)

    # STEP 4: extract coords (‡πÅ‡∏Å‡πâ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏à‡∏£‡∏¥‡∏á: lon, lat)
    progress.progress(80, text="‡∏î‡∏∂‡∏á lat/lon ‡∏à‡∏≤‡∏Å coords ...")
    df_exploded['coords'] = df_exploded['coords'].astype(str)
    df_exploded[['lon', 'lat']] = df_exploded['coords'].str.extract(
        r'(-?\d+\.\d+)\s*,\s*(-?\d+\.\d+)'
    ).astype(float)
    time.sleep(0.3)

    # STEP 5: drop missing
    progress.progress(100, text="‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ...")
    df_exploded = df_exploded.dropna(
        subset=["lat", "lon", "district", "subdistrict", "type_exploded"]
    )
    time.sleep(0.3)

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Quarter ‡πÅ‡∏•‡∏∞ Month ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå PM2.5
    df_exploded['quarter'] = df_exploded['timestamp_dt'].dt.quarter
    df_exploded['month'] = df_exploded['timestamp_dt'].dt.month
    df_exploded['year'] = df_exploded['timestamp_dt'].dt.year
    
    status.success("‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

    return df_exploded

# ---------------------------
# Function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ PM2.5 ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
# ---------------------------
def find_nearest_pm25(pm25_data, lat, lon, date, radius_km=2.0):
    """
    ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ PM2.5 ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡∏±‡∏î‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
    radius_km: ‡∏£‡∏±‡∏®‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏¥‡πÇ‡∏•‡πÄ‡∏°‡∏ï‡∏£
    """
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì)
    radius_deg = radius_km / 111.0  # 1 ‡∏≠‡∏á‡∏®‡∏≤ ‚âà 111 ‡∏Å‡∏°.
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
    date_only = pd.Timestamp(date).date()
    same_day_data = pm25_data[pd.to_datetime(pm25_data['date_dt']).dt.date == date_only]
    
    if len(same_day_data) == 0:
        return None
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á
    same_day_data = same_day_data.copy()
    same_day_data['distance'] = np.sqrt(
        (same_day_data['lat'] - lat) ** 2 + 
        (same_day_data['lon'] - lon) ** 2
    )
    
    # ‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏£‡∏±‡∏®‡∏°‡∏µ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
    nearby_stations = same_day_data[same_day_data['distance'] <= radius_deg]
    
    if len(nearby_stations) == 0:
        return None
    
    # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ PM2.5 ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
    return nearby_stations['pm2_5'].mean()

# ---------------------------
# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Streamlit App
# ---------------------------
st.set_page_config(page_title="Bangkok Complaint & PM2.5 Analysis", layout="wide")

# ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡πÉ‡∏ô filter
if 'filter_applied' not in st.session_state:
    st.session_state['filter_applied'] = False

# ---------------------------
# Tabs
# ---------------------------
tab_load, tab_main, tab_pm25 = st.tabs(["üìä Loading Status", "üìç Dashboard", "üò∑ PM2.5 Analysis"])

# ---------------------------
# Tab 1: Loading Status
# ---------------------------
with tab_load:
    st.subheader("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å..."):
        df = load_data_with_progress()
    
    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5..."):
        pm25_df = load_pm25_data_with_progress()
    
    col1, col2 = st.columns(2)
    with col1:
        st.success("‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞ cache ‡πÅ‡∏•‡πâ‡∏ß")
        st.info(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£: {len(df):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        st.write(f"‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤: {df['timestamp_dt'].min().date()} ‡∏ñ‡∏∂‡∏á {df['timestamp_dt'].max().date()}")
        
    with col2:
        st.success("‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞ cache ‡πÅ‡∏•‡πâ‡∏ß")
        st.info(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£: {len(pm25_df):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        st.write(f"‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤: {pm25_df['date_dt'].min().date()} ‡∏ñ‡∏∂‡∏á {pm25_df['date_dt'].max().date()}")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    with st.expander("üëÅÔ∏è ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5"):
        st.dataframe(pm25_df.head(10))

# ---------------------------
# Tab 2: Dashboard (Main)
# ---------------------------
with tab_main:
    # Sidebar Filter
    st.sidebar.header("Filters")
    
    districts = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df["district"].unique())
    selected_district = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ç‡∏ï", districts)

    subdistricts = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df["subdistrict"].unique())
    selected_subdistrict = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏Ç‡∏ß‡∏á", subdistricts)

    types = sorted(df["type_exploded"].unique())
    selected_types = st.sidebar.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤", types)

    # Organization dropdown (‡∏´‡∏•‡∏±‡∏Å)
    organizations = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df["organization"].dropna().unique())
    selected_org = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏´‡∏•‡∏±‡∏Å", organizations)

    # Organization List (‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
    all_org_lists = sorted(
        {org for lst in df["organization_list"] for org in lst if isinstance(lst, list)}
    )
    selected_org_multi = st.sidebar.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£ (organization_list)", all_org_lists)
    
    # Filtering
    df_filtered = df.copy()

    # ‡πÄ‡∏Ç‡∏ï
    if selected_district != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        df_filtered = df_filtered[df_filtered["district"] == selected_district]

    # ‡πÅ‡∏Ç‡∏ß‡∏á
    if selected_subdistrict != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        df_filtered = df_filtered[df_filtered["subdistrict"] == selected_subdistrict]

    # ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤
    if selected_types:
        df_filtered = df_filtered[df_filtered["type_exploded"].isin(selected_types)]

    # ‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏´‡∏•‡∏±‡∏Å
    if selected_org != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        df_filtered = df_filtered[df_filtered["organization"] == selected_org]

    # ‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (list)
    if selected_org_multi:
        df_filtered = df_filtered[
            df_filtered["organization_list"].apply(
                lambda lst: any(o in lst for o in selected_org_multi)
            )
        ]
        
    # -----------------------------
    # Time Filter (Thai Calendar UI)
    # -----------------------------
    st.sidebar.subheader("‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ (Timestamp)")
    
    # default range
    min_date = df["timestamp_dt"].min().date()
    max_date = df["timestamp_dt"].max().date()

    # date UI (show Thai locale)
    start_date = st.sidebar.date_input("‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (‡∏û.‡∏®.)", min_date)
    end_date = st.sidebar.date_input("‡∏ß‡∏±‡∏ô‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î (‡∏û.‡∏®.)", max_date)
    
    confirm_button = st.sidebar.button('‚úÖ Apply Filters', key='apply_main')

    # filter by datetime
    if confirm_button:
        df_filtered = df_filtered[
            (df_filtered["timestamp_dt"].dt.date >= start_date) &
            (df_filtered["timestamp_dt"].dt.date <= end_date)
        ]
    
    # -----------------------------
    # Display Metrics
    # -----------------------------
    st.header("üìà ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏´‡∏•‡∏±‡∏Å
    if selected_org != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        df_org = df_filtered[df_filtered["organization"] == selected_org]
        count_cases = len(df_org)

        if count_cases >= 50:
            avg_rating = df_org["star"].mean()
            st.metric("‚≠ê Rating ‡∏Ç‡∏≠‡∏á‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£", f"{avg_rating:.2f}")
        else:
            st.info(f"‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£ {selected_org} ‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤ {count_cases} ‡πÄ‡∏Ñ‡∏™ ‚Äî ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á Rating (‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 50 ‡πÄ‡∏Ñ‡∏™)")
    
    # -----------------------------
    # Cases Count by Time Range
    # -----------------------------
    st.subheader("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤")
    
    if len(df_filtered) > 0:
        now = df_filtered["timestamp_dt"].max()
        
        ranges = {
            "1 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": now - pd.Timedelta(days=1),
            "3 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": now - pd.Timedelta(days=3),
            "7 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": now - pd.Timedelta(days=7),
            "2 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": now - pd.Timedelta(days=14),
            "1 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": now - pd.Timedelta(days=30),
            "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": df_filtered["timestamp_dt"].min(),
        }

        cols = st.columns(3)
        for idx, (label, start_time) in enumerate(ranges.items()):
            count = df_filtered[df_filtered["timestamp_dt"] >= start_time].shape[0]
            with cols[idx % 3]:
                st.metric(label, f"{count:,} ‡πÄ‡∏Ñ‡∏™")
    else:
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
    
    # -----------------------------
    # Top 10 Bar Chart
    # -----------------------------
    st.subheader("‚≠ê Top 10 ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î")

    if df_filtered.empty:
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
    else:
        # 1. Groupby ‡πÅ‡∏•‡∏∞‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™ (Value Counts)
        top_10_types = df_filtered["type_exploded"].value_counts().nlargest(10).reset_index()
        top_10_types.columns = ["‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™"]

        # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Bar Chart
        fig = px.bar(
            top_10_types,
            x="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™",
            y="‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤",
            orientation='h',
            title="10 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î",
            color="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™",
            color_continuous_scale='Viridis'
        )
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á layout
        fig.update_layout(
            yaxis={'categoryorder':'total ascending'},
            plot_bgcolor='rgba(0,0,0,0)',
            xaxis=dict(showgrid=False)
        )

        st.plotly_chart(fig, use_container_width=True)
    
    # ---------------------------
    # Map with Clustering
    # ---------------------------
    st.header("üó∫Ô∏è ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ö‡∏ô‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà (DBSCAN Clustering)")

    if df_filtered.empty:
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
    else:
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà..."):
            df_map = prepare_map_data(df_filtered)

            # DBSCAN Clustering
            coords = df_map[["lat", "lon"]].to_numpy()
            clustering = DBSCAN(eps=0.002, min_samples=10).fit(coords)
            df_map["cluster"] = clustering.labels_
            
            # ‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
            if selected_org != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
                highlight_color = [0, 120, 255]   # ‡∏ü‡πâ‡∏≤
                normal_color = [180, 180, 180]    # ‡πÄ‡∏ó‡∏≤‡∏≠‡πà‡∏≠‡∏ô

                df_map["color"] = df_map["organization"].apply(
                    lambda x: highlight_color if x == selected_org else normal_color
                )

            elif selected_org_multi:
                highlight_color = [255, 100, 0]    # ‡∏™‡πâ‡∏°
                normal_color = [180, 180, 180]

                df_map["color"] = df_map["organization_list"].apply(
                    lambda lst: highlight_color if any(o in lst for o in selected_org_multi) else normal_color
                )

            else:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏µ‡∏™‡∏∏‡πà‡∏°‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞ cluster
                unique_clusters = sorted(df_map["cluster"].unique())
                colors = {
                    c: [np.random.randint(50,255), np.random.randint(50,255), np.random.randint(50,255)]
                    for c in unique_clusters
                }
                # cluster = -1 ‡∏Ñ‡∏∑‡∏≠ noise ‚Üí ‡∏™‡∏µ‡πÄ‡∏ó‡∏≤
                colors[-1] = [150,150,150]

                df_map["color"] = df_map["cluster"].apply(lambda c: colors[c])

            # PyDeck Visualization
            layer = pdk.Layer(
                "ScatterplotLayer",
                data=df_map,
                get_position='[lon, lat]',
                get_color="color",
                get_radius=40,
                pickable=True,
                opacity=0.7,
            )
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
            try:
                org_loc_df = pd.read_csv("dataset/bkk_osm_organization_locations.csv")
                org_loc_df['name_norm'] = org_loc_df['name'].str.strip().str.lower()
                df_map['organization_norm'] = df_map['organization'].fillna("").str.strip().str.lower()
                filtered_orgs = df_map['organization_norm'].unique()
                org_points = org_loc_df[org_loc_df['name_norm'].isin(filtered_orgs)].copy()
                
                if len(org_points) > 0:
                    layer_org = pdk.Layer(
                        "ScatterplotLayer",
                        data=org_points,
                        get_position=["lon", "lat"],
                        get_radius=200,
                        get_fill_color=[255, 0, 0, 180],
                        radius_min_pixels=8,
                        pickable=True,
                    )
                    layers = [layer, layer_org]
                else:
                    layers = [layer]
            except:
                layers = [layer]

            view_state = pdk.ViewState(
                latitude=df_map["lat"].mean(),
                longitude=df_map["lon"].mean(),
                zoom=11,
            )

            r = pdk.Deck(
                layers=layers,
                initial_view_state=view_state,
                tooltip={
                    "html": "<b>Cluster:</b> {cluster}<br>"
                            "<b>Type:</b> {type_exploded}<br>"
                            "<b>Organization:</b> {organization}<br>"
                            "<b>Lat:</b> {lat:.4f}<br>"
                            "<b>Lon:</b> {lon:.4f}",
                    "style": {"color": "white", "backgroundColor": "#333", "padding": "5px"}
                }
            )

            st.pydeck_chart(r)

# ---------------------------
# Tab 3: PM2.5 Analysis
# ---------------------------
with tab_pm25:
    st.header("üò∑ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå PM2.5 ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô")
    
    # Sidebar ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Filter PM2.5
    st.sidebar.header("PM2.5 Analysis Filters")
    
    # Filter ‡∏õ‡∏µ
    available_years = sorted(pm25_df['year'].unique())
    selected_year = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏µ", available_years, key='pm25_year')
    
    # Filter ‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™
    quarters = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(pm25_df['quarter'].unique())
    selected_quarter = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™", quarters, key='pm25_quarter')
    
    # Filter ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
    months = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(pm25_df['month'].unique())
    selected_month = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", months, key='pm25_month')
    
    # Filter ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
    districts_complaints = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df['district'].unique())
    selected_pm25_district = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ç‡∏ï (‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö)", districts_complaints, key='pm25_district')
    
    # Filter ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤
    complaint_types = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df['type_exploded'].unique())
    selected_complaint_type = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö)", complaint_types, key='pm25_type')
    
    # Filter PM2.5 Level
    pm25_range = st.sidebar.slider(
        "‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤ PM2.5 (¬µg/m¬≥)",
        min_value=int(pm25_df['pm2_5'].min()),
        max_value=int(pm25_df['pm2_5'].max()),
        value=(0, 100),
        key='pm25_range'
    )
    
    apply_pm25_filter = st.sidebar.button('üöÄ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå PM2.5', key='apply_pm25')
    
    if apply_pm25_filter:
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô..."):
            
            # ========================================
            # 1. ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5
            # ========================================
            pm25_filtered = pm25_df.copy()
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏µ
            pm25_filtered = pm25_filtered[pm25_filtered['year'] == selected_year]
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™
            if selected_quarter != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
                pm25_filtered = pm25_filtered[pm25_filtered['quarter'] == selected_quarter]
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
            if selected_month != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
                pm25_filtered = pm25_filtered[pm25_filtered['month'] == selected_month]
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤ PM2.5
            pm25_filtered = pm25_filtered[
                (pm25_filtered['pm2_5'] >= pm25_range[0]) & 
                (pm25_filtered['pm2_5'] <= pm25_range[1])
            ]
            
            # ========================================
            # 2. ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
            # ========================================
            complaints_filtered = df.copy()
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö PM2.5
            complaints_filtered = complaints_filtered[complaints_filtered['year'] == selected_year]
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™
            if selected_quarter != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
                complaints_filtered = complaints_filtered[complaints_filtered['quarter'] == selected_quarter]
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
            if selected_month != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
                complaints_filtered = complaints_filtered[complaints_filtered['month'] == selected_month]
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏Ç‡∏ï
            if selected_pm25_district != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
                complaints_filtered = complaints_filtered[complaints_filtered['district'] == selected_pm25_district]
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤
            if selected_complaint_type != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
                complaints_filtered = complaints_filtered[complaints_filtered['type_exploded'] == selected_complaint_type]
            
            # ========================================
            # 3. ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
            # ========================================
            st.subheader("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("üìÖ ‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå", selected_year)
                st.metric("üìà ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ PM2.5", f"{len(pm25_filtered):,}")
                avg_pm25 = pm25_filtered['pm2_5'].mean()
                st.metric("üå´Ô∏è ‡∏Ñ‡πà‡∏≤ PM2.5 ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢", f"{avg_pm25:.1f} ¬µg/m¬≥")
            
            with col2:
                quarter_text = f"‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™ {selected_quarter}" if selected_quarter != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" else "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"
                st.metric("üìä ‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™", quarter_text)
                st.metric("üìù ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", f"{len(complaints_filtered):,}")
                if len(complaints_filtered) > 0:
                    avg_rating = complaints_filtered['star'].mean()
                    st.metric("‚≠ê ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢", f"{avg_rating:.2f}")
                else:
                    st.metric("‚≠ê ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢", "N/A")
            
            with col3:
                month_text = f"‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {selected_month}" if selected_month != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" else "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"
                st.metric("üóìÔ∏è ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", month_text)
                if selected_pm25_district != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
                    st.metric("üìç ‡πÄ‡∏Ç‡∏ï", selected_pm25_district)
                else:
                    st.metric("üìç ‡πÄ‡∏Ç‡∏ï", "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
                
                if selected_complaint_type != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
                    st.metric("üîß ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤", selected_complaint_type)
                else:
                    st.metric("üîß ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤", "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
            
            # ========================================
            # 4. Visualization: PM2.5 ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤
            # ========================================
            st.subheader("üìà ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Ñ‡πà‡∏≤ PM2.5 ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤")
            
            if len(pm25_filtered) > 0:
                # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
                pm25_daily = pm25_filtered.groupby('date_dt')['pm2_5'].mean().reset_index()
                pm25_daily.sort_values('date_dt', inplace=True)
                
                fig_pm25 = px.line(
                    pm25_daily,
                    x='date_dt',
                    y='pm2_5',
                    title=f'‡∏Ñ‡πà‡∏≤ PM2.5 ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô ({selected_year})',
                    labels={'date_dt': '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', 'pm2_5': 'PM2.5 (¬µg/m¬≥)'},
                    markers=True
                )
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏™‡πâ‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô WHO (15 ¬µg/m¬≥)
                fig_pm25.add_hline(
                    y=15, 
                    line_dash="dash", 
                    line_color="red",
                    annotation_text="‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô WHO (15 ¬µg/m¬≥)",
                    annotation_position="bottom right"
                )
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏™‡πâ‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÑ‡∏ó‡∏¢ (50 ¬µg/m¬≥)
                fig_pm25.add_hline(
                    y=50, 
                    line_dash="dash", 
                    line_color="orange",
                    annotation_text="‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÑ‡∏ó‡∏¢ (50 ¬µg/m¬≥)",
                    annotation_position="top right"
                )
                
                fig_pm25.update_layout(
                    xaxis_title="‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà",
                    yaxis_title="PM2.5 (¬µg/m¬≥)",
                    hovermode='x unified'
                )
                
                st.plotly_chart(fig_pm25, use_container_width=True)
            else:
                st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
            
                        # ========================================
            # 5. Visualization: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏±‡∏ö PM2.5
            # ========================================
            st.subheader("üìä ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö PM2.5")
            
            if len(complaints_filtered) > 0 and len(pm25_filtered) > 0:
                # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
                complaints_daily = complaints_filtered.groupby(
                    complaints_filtered['timestamp_dt'].dt.date
                ).size().reset_index(name='complaint_count')
                complaints_daily['timestamp_dt'] = pd.to_datetime(complaints_daily['timestamp_dt'])
                
                # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° PM2.5 ‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
                pm25_daily_avg = pm25_filtered.groupby('date_dt')['pm2_5'].mean().reset_index()
                
                # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                merged_data = pd.merge(
                    complaints_daily,
                    pm25_daily_avg,
                    left_on='timestamp_dt',
                    right_on='date_dt',
                    how='inner'
                )
                
                if len(merged_data) > 0:
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì correlation ‡∏Å‡πà‡∏≠‡∏ô
                    correlation = merged_data['pm2_5'].corr(merged_data['complaint_count'])
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á scatter plot (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ trendline='ols')
                    fig_scatter = px.scatter(
                        merged_data,
                        x='pm2_5',
                        y='complaint_count',
                        title=f'‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö PM2.5 ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô (Correlation: {correlation:.3f})',
                        labels={'pm2_5': 'PM2.5 (¬µg/m¬≥)', 'complaint_count': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô'},
                        hover_data=['timestamp_dt'],
                        trendline=None  # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ trendline ‡∏à‡∏≤‡∏Å statsmodels
                    )
                    
                    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏™‡πâ‡∏ô regression ‡∏î‡πâ‡∏ß‡∏¢ numpy (‡∏ñ‡πâ‡∏≤ correlation ‡∏™‡∏π‡∏á‡∏û‡∏≠)
                    if abs(correlation) > 0.2:
                        try:
                            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏™‡πâ‡∏ô regression ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢
                            x = merged_data['pm2_5'].values
                            y = merged_data['complaint_count'].values
                            
                            # ‡πÉ‡∏ä‡πâ numpy ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö linear regression
                            coeff = np.polyfit(x, y, 1)
                            poly = np.poly1d(coeff)
                            
                            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏™‡πâ‡∏ô regression
                            x_line = np.linspace(x.min(), x.max(), 100)
                            y_line = poly(x_line)
                            
                            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏™‡πâ‡∏ô‡∏•‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏≤‡∏ü
                            fig_scatter.add_trace(
                                go.Scatter(
                                    x=x_line,
                                    y=y_line,
                                    mode='lines',
                                    name='‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°',
                                    line=dict(color='red', dash='dash'),
                                    showlegend=True
                                )
                            )
                            
                            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏°‡∏Å‡∏≤‡∏£ regression
                            equation = f'y = {coeff[0]:.3f}x + {coeff[1]:.3f}'
                            fig_scatter.update_layout(
                                annotations=[
                                    dict(
                                        x=0.05, y=0.95,
                                        xref="paper", yref="paper",
                                        text=f"Correlation: {correlation:.3f}<br>Regression: {equation}",
                                        showarrow=False,
                                        bgcolor="white",
                                        bordercolor="black",
                                        borderwidth=1
                                    )
                                ]
                            )
                        except:
                            # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì regression ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
                            fig_scatter.update_layout(
                                annotations=[
                                    dict(
                                        x=0.05, y=0.95,
                                        xref="paper", yref="paper",
                                        text=f"Correlation: {correlation:.3f}",
                                        showarrow=False,
                                        bgcolor="white",
                                        bordercolor="black",
                                        borderwidth=1
                                    )
                                ]
                            )
                    
                    fig_scatter.update_layout(
                        showlegend=True
                    )
                    
                    st.plotly_chart(fig_scatter, use_container_width=True)
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå
                    st.subheader("üìà ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå")
                    
                    col_corr1, col_corr2 = st.columns(2)
                    
                    with col_corr1:
                        st.metric("‡∏Ñ‡πà‡∏≤‡∏™‡∏´‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå (Correlation)", f"{correlation:.3f}")
                        
                        # ‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏° correlation
                        if correlation > 0.7:
                            st.success("üî¥ **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏≤‡∏á‡∏ö‡∏ß‡∏Å‡∏ó‡∏µ‡πà‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á‡∏°‡∏≤‡∏Å**")
                            st.write("PM2.5 ‡∏™‡∏π‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô")
                        elif correlation > 0.5:
                            st.success("üü† **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏≤‡∏á‡∏ö‡∏ß‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á**")
                            st.write("PM2.5 ‡∏™‡∏π‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô")
                        elif correlation > 0.3:
                            st.info("üü° **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏≤‡∏á‡∏ö‡∏ß‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏≠‡πà‡∏≠‡∏ô**")
                            st.write("PM2.5 ‡∏™‡∏π‡∏á‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô")
                        elif correlation > -0.3:
                            st.warning("‚ö™ **‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô**")
                            st.write("‡∏£‡∏∞‡∏î‡∏±‡∏ö PM2.5 ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ô")
                        elif correlation > -0.5:
                            st.info("üü¢ **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏≤‡∏á‡∏•‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏≠‡πà‡∏≠‡∏ô**")
                            st.write("PM2.5 ‡∏™‡∏π‡∏á‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏•‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô")
                        elif correlation > -0.7:
                            st.success("üîµ **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏≤‡∏á‡∏•‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á**")
                            st.write("PM2.5 ‡∏™‡∏π‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏•‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô")
                        else:
                            st.success("üü£ **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏≤‡∏á‡∏•‡∏ö‡∏ó‡∏µ‡πà‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á‡∏°‡∏≤‡∏Å**")
                            st.write("PM2.5 ‡∏™‡∏π‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏•‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô")
                    
                    with col_corr2:
                        # ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
                        st.metric("‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤ PM2.5", f"{merged_data['pm2_5'].min():.1f} - {merged_data['pm2_5'].max():.1f} ¬µg/m¬≥")
                        st.metric("‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", f"{merged_data['complaint_count'].min()} - {merged_data['complaint_count'].max()} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á/‡∏ß‡∏±‡∏ô")
                        
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ PM2.5 ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î
                        max_pm25_day = merged_data.loc[merged_data['pm2_5'].idxmax()]
                        min_pm25_day = merged_data.loc[merged_data['pm2_5'].idxmin()]
                        
                        st.write("**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà PM2.5 ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î:**")
                        st.write(f"- ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {max_pm25_day['timestamp_dt'].date()}")
                        st.write(f"- ‡∏Ñ‡πà‡∏≤ PM2.5: {max_pm25_day['pm2_5']:.1f} ¬µg/m¬≥")
                        st.write(f"- ‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô: {max_pm25_day['complaint_count']} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
                        
                        st.write("**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà PM2.5 ‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î:**")
                        st.write(f"- ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {min_pm25_day['timestamp_dt'].date()}")
                        st.write(f"- ‡∏Ñ‡πà‡∏≤ PM2.5: {min_pm25_day['pm2_5']:.1f} ¬µg/m¬≥")
                        st.write(f"- ‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô: {min_pm25_day['complaint_count']} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                    with st.expander("üìã ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô"):
                        st.dataframe(
                            merged_data[['timestamp_dt', 'pm2_5', 'complaint_count']].sort_values('pm2_5', ascending=False),
                            use_container_width=True
                        )
                        
                else:
                    st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5")
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ
                    st.info("**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ:**")
                    st.write("1. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ß‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô")
                    st.write("2. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô")
                    st.write("3. ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ")
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
                    if len(complaints_daily) > 0:
                        st.write(f"üìÖ ‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {complaints_daily['timestamp_dt'].min().date()} ‡∏ñ‡∏∂‡∏á {complaints_daily['timestamp_dt'].max().date()}")
                    if len(pm25_daily_avg) > 0:
                        st.write(f"üå´Ô∏è PM2.5 ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {pm25_daily_avg['date_dt'].min().date()} ‡∏ñ‡∏∂‡∏á {pm25_daily_avg['date_dt'].max().date()}")
            else:
                st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏´‡∏£‡∏∑‡∏≠ PM2.5 ‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
                
                # ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
                if len(complaints_filtered) == 0:
                    st.write("‚ùå **‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô** - ‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç:")
                    st.write("- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ")
                    st.write("- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏≠‡∏∑‡πà‡∏ô")
                    st.write("- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ç‡∏ï‡∏≠‡∏∑‡πà‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ç‡∏ï")
                    
                if len(pm25_filtered) == 0:
                    st.write("‚ùå **‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5** - ‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç:")
                    st.write("- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ")
                    st.write("- ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤ PM2.5")
                    st.write("- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏≠‡∏∑‡πà‡∏ô")
            
            # ========================================
            # 6. Heatmap: PM2.5 ‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø
            # ========================================
            st.subheader("üó∫Ô∏è Heatmap ‡∏Ñ‡πà‡∏≤ PM2.5 ‡πÉ‡∏ô‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø")
            
            if len(pm25_filtered) > 0:
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ PM2.5 ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
                pm25_locations = pm25_filtered.groupby(['lat', 'lon'])['pm2_5'].mean().reset_index()
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap Layer
                heatmap_layer = pdk.Layer(
                    "HeatmapLayer",
                    data=pm25_locations,
                    get_position=['lon', 'lat'],
                    get_weight='pm2_5',
                    radius_pixels=30,
                    intensity=1,
                    threshold=0.1,
                    opacity=0.8,
                    pickable=True
                )
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
                if len(complaints_filtered) > 0:
                    complaints_layer = pdk.Layer(
                        "ScatterplotLayer",
                        data=complaints_filtered,
                        get_position=['lon', 'lat'],
                        get_color=[255, 0, 0, 180],
                        get_radius=50,
                        pickable=True,
                        opacity=0.7
                    )
                    layers = [heatmap_layer, complaints_layer]
                else:
                    layers = [heatmap_layer]
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á
                if len(pm25_locations) > 0:
                    center_lat = pm25_locations['lat'].mean()
                    center_lon = pm25_locations['lon'].mean()
                else:
                    center_lat = 13.7563
                    center_lon = 100.5018
                
                view_state = pdk.ViewState(
                    latitude=center_lat,
                    longitude=center_lon,
                    zoom=10,
                    pitch=0
                )
                
                tooltip = {
                    "html": "<b>PM2.5:</b> {pm2_5:.1f} ¬µg/m¬≥<br><b>Lat:</b> {lat:.4f}<br><b>Lon:</b> {lon:.4f}",
                    "style": {"color": "white", "backgroundColor": "#333", "padding": "5px"}
                }
                
                r = pdk.Deck(
                    layers=layers,
                    initial_view_state=view_state,
                    tooltip=tooltip,
                    map_style='mapbox://styles/mapbox/light-v10'
                )
                
                st.pydeck_chart(r)
                
                # ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ PM2.5 ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
                st.subheader("üö® ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ PM2.5 ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î")
                top_pm25_areas = pm25_filtered.groupby(['lat', 'lon'])['pm2_5'].mean().nlargest(5).reset_index()
                
                for idx, row in top_pm25_areas.iterrows():
                    st.write(f"{idx+1}. ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ({row['lat']:.4f}, {row['lon']:.4f}): {row['pm2_5']:.1f} ¬µg/m¬≥")
            
            # ========================================
            # 7. ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
            # ========================================
            st.subheader("üìã ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö")
            
            if len(pm25_filtered) > 0:
                # ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
                pm25_monthly = pm25_filtered.groupby('month').agg({
                    'pm2_5': ['mean', 'max', 'min', 'count']
                }).round(2)
                pm25_monthly.columns = ['‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢', '‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î', '‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•']
                pm25_monthly = pm25_monthly.reset_index()
                
                # ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
                if len(complaints_filtered) > 0:
                    complaints_monthly = complaints_filtered.groupby('month').size().reset_index(name='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô')
                    
                    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                    comparison_df = pd.merge(
                        pm25_monthly,
                        complaints_monthly,
                        on='month',
                        how='left'
                    )
                    comparison_df['‡πÄ‡∏î‡∏∑‡∏≠‡∏ô'] = comparison_df['month'].apply(lambda x: f'‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {x}')
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á
                    st.dataframe(
                        comparison_df[['‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢', '‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î', '‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô']],
                        use_container_width=True
                    )
                else:
                    pm25_monthly['‡πÄ‡∏î‡∏∑‡∏≠‡∏ô'] = pm25_monthly['month'].apply(lambda x: f'‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {x}')
                    st.dataframe(
                        pm25_monthly[['‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢', '‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î', '‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•']],
                        use_container_width=True
                    )
                    
                    st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
    
    else:
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        st.info("üëà ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå PM2.5' ‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")
            st.dataframe(pm25_df[['date_str', 'lat', 'lon', 'pm2_5', 'quarter', 'month']].head(10))
            
        with col2:
            st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")
            st.dataframe(df[['timestamp_dt', 'type_exploded', 'district', 'organization', 'quarter', 'month']].head(10))
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
        st.subheader("üìà ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
        
        col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
        
        with col_stat1:
            st.metric("‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", f"{len(available_years)} ‡∏õ‡∏µ")
        
        with col_stat2:
            st.metric("‡∏Ñ‡πà‡∏≤ PM2.5 ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{pm25_df['pm2_5'].mean():.1f} ¬µg/m¬≥")
        
        with col_stat3:
            st.metric("‡∏Ñ‡πà‡∏≤ PM2.5 ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î", f"{pm25_df['pm2_5'].max():.1f} ¬µg/m¬≥")
        
        with col_stat4:
            st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{len(pm25_df):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")